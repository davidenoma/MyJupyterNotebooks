{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk.get_word_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-de6024717cb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_word_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk.get_word_features'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [('I love this car', 'positive'),\n",
    "              ('This view is amazing', 'positive'),\n",
    "              ('I feel great this morning', 'positive'),\n",
    "              ('I am so excited about the concert', 'positive'),\n",
    "              ('He is my best friend', 'positive')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tweets = [('I do not like this car', 'negative'),\n",
    "              ('This view is horrible', 'negative'),\n",
    "              ('I feel tired this morning', 'negative'),\n",
    "              ('I am not looking forward to the concert', 'negative'),\n",
    "              ('He is my enemy', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take both of those lists and create a single list of tuples each containing two elements. \n",
    "#First element is an array containing the words and second element is the type of sentiment. \n",
    "#We get rid of the words smaller than 2 characters and we use lowercase for everything.\n",
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if len(e) >= 3] \n",
    "    tweets.append((words_filtered, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['love', 'this', 'car'], 'positive'),\n",
       " (['this', 'view', 'amazing'], 'positive'),\n",
       " (['feel', 'great', 'this', 'morning'], 'positive'),\n",
       " (['excited', 'about', 'the', 'concert'], 'positive'),\n",
       " (['best', 'friend'], 'positive'),\n",
       " (['not', 'like', 'this', 'car'], 'negative'),\n",
       " (['this', 'view', 'horrible'], 'negative'),\n",
       " (['feel', 'tired', 'this', 'morning'], 'negative'),\n",
       " (['not', 'looking', 'forward', 'the', 'concert'], 'negative'),\n",
       " (['enemy'], 'negative')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = [\n",
    "    (['feel', 'happy', 'this', 'morning'], 'positive'),\n",
    "    (['larry', 'friend'], 'positive'),\n",
    "    (['not', 'like', 'that', 'man'], 'negative'),\n",
    "    (['house', 'not', 'great'], 'negative'),\n",
    "    (['your', 'song', 'annoying'], 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier\n",
    "#The list of word features need to be extracted from the tweets. It is a list with every distinct words ordered \n",
    "#by frequency of appearance. We use the following function to get the list plus the two helper functions.\n",
    "def get_words_in_tweets(tweets):\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "      all_words.extend(words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = get_word_features(get_words_in_tweets(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['love', 'this', 'car', 'view', 'amazing', 'feel', 'great', 'morning', 'excited', 'about', 'the', 'concert', 'best', 'friend', 'not', 'like', 'horrible', 'tired', 'looking', 'forward', 'enemy'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a classifier, we need to decide what features are relevant. To do that, we first need a feature extractor. \n",
    "#The one we are going to use returns a dictionary indicating what words are contained in the input passed. \n",
    "#Here, the input is the tweet. We use the word features list defined above along with the input to create the dictionary.\n",
    "\n",
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document =  ['love', 'this', 'car'] \n",
    "feat = extract_features(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains(love)': True,\n",
       " 'contains(this)': True,\n",
       " 'contains(car)': True,\n",
       " 'contains(view)': False,\n",
       " 'contains(amazing)': False,\n",
       " 'contains(feel)': False,\n",
       " 'contains(great)': False,\n",
       " 'contains(morning)': False,\n",
       " 'contains(excited)': False,\n",
       " 'contains(about)': False,\n",
       " 'contains(the)': False,\n",
       " 'contains(concert)': False,\n",
       " 'contains(best)': False,\n",
       " 'contains(friend)': False,\n",
       " 'contains(not)': False,\n",
       " 'contains(like)': False,\n",
       " 'contains(horrible)': False,\n",
       " 'contains(tired)': False,\n",
       " 'contains(looking)': False,\n",
       " 'contains(forward)': False,\n",
       " 'contains(enemy)': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'contains(love)': True, 'contains(this)': True, 'contains(car)': True, 'contains(view)': False, 'contains(amazing)': False, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False}, 'positive'), ({'contains(love)': False, 'contains(this)': True, 'contains(car)': False, 'contains(view)': True, 'contains(amazing)': True, 'contains(feel)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(excited)': False, 'contains(about)': False, 'contains(the)': False, 'contains(concert)': False, 'contains(best)': False, 'contains(friend)': False, 'contains(not)': False, 'contains(like)': False, 'contains(horrible)': False, 'contains(tired)': False, 'contains(looking)': False, 'contains(forward)': False, 'contains(enemy)': False}, 'positive'), ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x218d31f3828>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ELEProbDist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-be40a4483006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mELEProbDist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Create the P(label) distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlabel_probdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ELEProbDist' is not defined"
     ]
    }
   ],
   "source": [
    "def train(labeled_featuresets, estimator=ELEProbDist):\n",
    "    \n",
    "    # Create the P(label) distribution\n",
    "    label_probdist = estimator(label_freqdist)\n",
    "\n",
    "    # Create the P(fval|label, fname) distribution\n",
    "    feature_probdist = {}\n",
    "    \n",
    "    return NaiveBayesClassifier(label_probdist, feature_probdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
